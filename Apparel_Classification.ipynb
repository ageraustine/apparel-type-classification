{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKJgTHIAYvAro0iyw+ahyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ageraustine/apparel-type-classification/blob/master/Apparel_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                    Data Fetching and Cleansing"
      ],
      "metadata": {
        "id": "1AnI2gP4TBbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B5NfP2E1Syl5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "styles_path = '/content/drive/MyDrive/datasets/fashion_dataset/styles.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUOFnc6ATPrw",
        "outputId": "c5f1e214-37f9-45f9-e164-540cc37b0f93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_dir = '/content/drive/MyDrive/datasets/fashion_dataset/fashion_products.zip'\n",
        "dataset_dir = os.getcwd() + '/dataset'\n",
        "\n",
        "with zipfile.ZipFile(zip_dir, \"r\") as zp:\n",
        "  zp.extractall(dataset_dir)"
      ],
      "metadata": {
        "id": "iyTtwZhqTRCe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "                Categorization Utilities"
      ],
      "metadata": {
        "id": "DmdCc05WTlna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize(dataframe, idx, source, dest)->dict:\n",
        "    \"\"\"\n",
        "    accepts fours arguments i.e dataframe, idx, source, dest\n",
        "\n",
        "    returns a dictionary containing arrays as values\n",
        "    \"\"\"\n",
        "    categories = {}\n",
        "    for id in idx:\n",
        "        img_category = dataframe.loc[dataframe[source] == id, dest].to_list()[0]\n",
        "        current_img = str(id) + \".jpg\"\n",
        "        if img_category in categories:\n",
        "            values = categories[img_category]\n",
        "            values.append(current_img)\n",
        "            categories[img_category] = values\n",
        "        else:\n",
        "            categories[img_category] = [current_img]\n",
        "    return categories\n",
        "\n",
        "def copy_images(image_dict, source, dest):\n",
        "    \"\"\"\n",
        "    Accepts image dictionary, source directory and target directory args\n",
        "\n",
        "    copies images into categorized directories\n",
        "    \"\"\"\n",
        "    for key, val in image_dict.items():\n",
        "        dest_image_dir = f\"{dest}/{key}\"\n",
        "        if(not os.path.exists(dest_image_dir)):\n",
        "            os.makedirs(dest_image_dir)\n",
        "        for image in val:\n",
        "            source_img_path = f\"{source}/{image}\"\n",
        "            dest_img_path = f\"{dest_image_dir}/{image}\"\n",
        "            if(os.path.exists(source_img_path)):\n",
        "                if(not os.path.exists(dest_img_path)):\n",
        "                    shutil.copyfile(source_img_path, dest_img_path)\n"
      ],
      "metadata": {
        "id": "rt9XUW2fTVP8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "                       Categorization of The Dataset\n",
        "The fashion product dataset is categorized based on articleType column. This splits the data into various groups i.e shirts, trousers, watches etc                       "
      ],
      "metadata": {
        "id": "VsHh0nQcTuWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the styles csv file\n",
        "styles_dir = '/content/drive/MyDrive/datasets/fashion_dataset/styles.csv'\n",
        "fashion_df = pd.read_csv(styles_dir, on_bad_lines='skip')\n",
        "ids = fashion_df['id']\n",
        "\n",
        "# Categorize the images based on article type i.e shirts, trousers etc\n",
        "article_categories = categorize(fashion_df, ids, 'id', 'articleType')"
      ],
      "metadata": {
        "id": "4gQ2Y9SUTaLO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy images from source directories to a directory with class sub-directories\n",
        "source_dir = f\"{dataset_dir}/images\"\n",
        "dest_dir = f\"{dataset_dir}/articleType\"\n",
        "copy_images(article_categories, source_dir, dest_dir)"
      ],
      "metadata": {
        "id": "uGZ4uJ-uTdpe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "               DATASET LOADING"
      ],
      "metadata": {
        "id": "cvohl-2VWfQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "EYK-a30VWe3I"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    dest_dir,\n",
        "    subset = \"training\",\n",
        "    validation_split = 0.2,\n",
        "    seed=132,\n",
        "    batch_size= BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "DzoexiFnWyQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "                      Data Preprocessing"
      ],
      "metadata": {
        "id": "eqQVsEVkYET5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Rescaling(1/225),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ]\n",
        ")\n",
        "dataset = dataset.map(lambda x,y:(data_augmentation(x), y))"
      ],
      "metadata": {
        "id": "EeUcPdsOX-lz"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}